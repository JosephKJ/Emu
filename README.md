<div align="center">

<h2>Emu: Open Multimodal Generalists from BAAI</h2>


</div>

---


- [**Emu1**](Emu1) (Arxiv 2023) - Generative Pretraining in Multimodality

- [**Emu2**](Emu2) (Arxiv 2023) - Generative Multimodal Models are In-Context Learners

## News
- 2023.7 Inference code and model of Emu1 are available.
- 2023.12 Inference code, model and Demo of Emu2 are available. Enjoy the [Demo](https://huggingface.co/spaces/BAAI/Emu2).

## Hightlights
- State-of-the-art performance
- Next-generation capabilities
- A base model for diverse tasks

## Contact
- **We are hiring** at all levels at BAAI Vision Team, including full-time researchers, engineers and interns. 
If you are interested in working with us on **foundation model, visual perception and multimodal learning**, please contact [Xinlong Wang](https://www.xloong.wang/) (`wangxinlong@baai.ac.cn`).


<!-- 
## License

The content of this project itself is licensed under [LICENSE](). -->
